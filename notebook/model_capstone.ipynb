{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8616ca2-ddc9-4b20-b681-11ac0142cb73",
   "metadata": {},
   "source": [
    "## Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a0eb3-5ca0-4b06-895a-c5ba9ef9a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the necessary libraries for audio visualization\n",
    "!pip install librosa\n",
    "!pip install IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec4ecff-2707-44e3-abec-7ced203e796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting an audio file\n",
    "filename='Healthy/1.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514763d-3919-4810-a3f0-53e379ca03df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries for visualizations\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b14c5-2a1e-4bce-9ef0-4c8df7ca5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing and playing one audio\n",
    "plt.figure(figsize=(8,2))\n",
    "data, sample_rate=librosa.load(filename)\n",
    "librosa.display.waveshow(data, sr=sample_rate)\n",
    "ipd.Audio(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7ac09-4461-4847-90ca-621eb5e1f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the sample rate\n",
    "sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac504827-26a5-4c5e-9bc9-f1e3dcc52c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile as wav\n",
    "wave_sample_rate, wave_audio = wav.read(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de69a5d7-b152-4176-a7c9-392a0fab5e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecadc0f-3620-4616-a133-8d138ebd5437",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610ea3e-5303-4c2d-80a5-9c3bf33656b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f03afd7-82e2-4ca3-a3c7-ae678bfc6644",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb367bc-4b46-4f6a-8dd9-fe6c225cfd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "\n",
    "# Function to load and play the audio\n",
    "def load_play(filename):\n",
    "    data, sample_rate = librosa.load(filename)\n",
    "    display(ipd.Audio(filename))\n",
    "    return data, sample_rate\n",
    "\n",
    "# Adding gaussian noise to the audio\n",
    "def add_gaussian_noise(audio_data, stddev=0.01):\n",
    "    noise = np.random.normal(0, stddev, audio_data.shape)\n",
    "    noisy_audio = audio_data + noise\n",
    "    return noisy_audio\n",
    "\n",
    "# Saving the audio files\n",
    "def save_audio(file_path, audio_data, sample_rate):\n",
    "    sf.write(file_path, audio_data, sample_rate)\n",
    "\n",
    "# Function to copy original audios the new folder\n",
    "def copy(folder_path, output_folder):\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.wav')]\n",
    "\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        output_file_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "        shutil.copy(file_path, output_file_path)\n",
    "\n",
    "\n",
    "# Processing all audio files\n",
    "def process_audio(folder_path, output_folder, stddev=0.01):\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.wav')]\n",
    "\n",
    "    category = os.path.basename(folder_path)\n",
    "\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Displaying the original audio\n",
    "        print(f\"o_audio ({category}): {file_name}\")\n",
    "        data, sample_rate = load_play(file_path)\n",
    "\n",
    "        # Adding Gaussian noise to the audio\n",
    "        noisy_data = add_gaussian_noise(data, stddev)\n",
    "\n",
    "        # Saving the noisy audio to a new folder\n",
    "        noisy_file_name = f'n_{file_name}'\n",
    "        noisy_file_path = os.path.join(output_folder, noisy_file_name)\n",
    "        save_audio(noisy_file_path, noisy_data, sample_rate)\n",
    "\n",
    "        # Play the noisy audio\n",
    "        print(f\"n_audio ({category}): {noisy_file_name}\")\n",
    "        load_play(noisy_file_path)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "healthy_data = 'Healthy'\n",
    "unhealthy_data = 'Unhealthy'\n",
    "healthy_audio = 'new_healthy_data'\n",
    "unhealthy_audio = 'new_unhealthy_data'\n",
    "\n",
    "# Creating new folders to save the audios in case they don't exist\n",
    "os.makedirs(healthy_audio, exist_ok=True)\n",
    "os.makedirs(unhealthy_audio, exist_ok=True)\n",
    "\n",
    "# Copying the original audio files to the new folders\n",
    "copy(healthy_data, healthy_audio)\n",
    "copy(unhealthy_data, unhealthy_audio)\n",
    "\n",
    "# Processing the audio files and saving noisy audio\n",
    "process_audio(healthy_data, healthy_audio, stddev=0.01)\n",
    "process_audio(unhealthy_data, unhealthy_audio, stddev=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ceb7a9-9146-4858-a239-6f2e37ce408c",
   "metadata": {},
   "source": [
    "## Feature Extraction using MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9028a2-a404-47ae-a12e-8f8f848c89a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Defining folder paths\n",
    "healthy_data = 'new_healthy_data'\n",
    "unhealthy_data = 'new_unhealthy_data'\n",
    "\n",
    "# Extracting MFCC features\n",
    "def features_extractor(file_path, n_mfcc=40):\n",
    "    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "    # mfccs_scaled_features = (mfccs_scaled_features - np.mean(mfccs_scaled_features)) / np.std(mfccs_scaled_features)\n",
    "    return mfccs_scaled_features\n",
    "\n",
    "# Initializing an empty list to store features\n",
    "extracted_features = []\n",
    "\n",
    "# Processing healthy audio files\n",
    "for file_name in tqdm(os.listdir(healthy_data)):\n",
    "    if file_name.endswith('.wav'):\n",
    "        file_path = os.path.join(healthy_data, file_name)\n",
    "        features = features_extractor(file_path)\n",
    "        extracted_features.append([features, 'healthy'])\n",
    "\n",
    "# Processing unhealthy audio files\n",
    "for file_name in tqdm(os.listdir(unhealthy_data)):\n",
    "    if file_name.endswith('.wav'):\n",
    "        file_path = os.path.join(unhealthy_data, file_name)\n",
    "        features = features_extractor(file_path)\n",
    "        extracted_features.append([features, 'unhealthy'])\n",
    "\n",
    "# Convert extracted features to a DataFrame\n",
    "extracted_features_df = pd.DataFrame(extracted_features, columns=['feature', 'label'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_csv = 'audio_features_df.csv'\n",
    "extracted_features_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Features and labels saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052a30a-0e1e-4349-a3c7-48c5707f5fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting the dataset into independent and dependent dataset\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607c4d5-6392-49ca-a82f-cdf8c6d0c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a0a7d-9253-42fe-9755-1e9d4843cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Encoding\n",
    "### Label Encoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d741c-f2bc-43dc-bc46-ed2c662793c3",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3792e3-1ee0-4262-99fa-70cfe4efe19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adba134-672b-4644-9249-872655ffc452",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf46bf6-1b31-4d68-8354-202865bb1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b601fc-ae63-4fe3-a7d2-a8025e043470",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a638d444-e0d1-452a-a486-20ce4342407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d6ffb-066d-41ae-8c6f-178d4dd60b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further split test dataset into validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6979e7-19e7-47f5-93b0-1a5e2ef18878",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa09b1-5623-44ae-809c-5111e3b4a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c5450-9171-41e5-adf8-15bee2002d0e",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027dcc8-8309-4b6f-b85a-55ef0118bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Building the model\n",
    "def build_light_vgg11(input_shape=(40, 1, 1), num_classes=2):\n",
    "    # Input layer\n",
    "    \n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Feature extraction (VGG11-like architecture)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.01))(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 1))(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 1))(x)\n",
    "    \n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    # x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 1))(x)\n",
    "    \n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "    #x = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 1))(x)\n",
    "    \n",
    "    # Custom lightweight block\n",
    "    x = layers.Conv2D(128, (1, 1), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(1, (1, 1), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Global average pooling and sigmoid activation\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model = build_light_vgg11(input_shape=(40, 1, 1), num_classes=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da831575-ed40-4037-bca3-79658379936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the data\n",
    "X_train = X_train.reshape(-1, 40, 1, 1)\n",
    "X_val = X_val.reshape(-1, 40, 1, 1)\n",
    "X_test = X_test.reshape(-1, 40, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55811b2-7b02-4975-9d07-54f6905b1dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More data augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db9211f-b4c3-4cff-82a0-25f50c099fbb",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca14b457-daa2-4b2e-a544-c62a21eff993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Callbacks for early stopping and saving the best model\n",
    "callbacks = [\n",
    "    ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min', verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "]\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluating the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b88804-9b77-4f51-b749-8d023371deee",
   "metadata": {},
   "source": [
    "## Getting the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d17a7-f65f-41b6-9cf9-fa50cfb68dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Getting model predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1) \n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generating classification report\n",
    "report = classification_report(y_true, y_pred, digits=4)\n",
    "\n",
    "# Printing the report\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f77ada-da50-4f02-a9ba-b6610084eb0f",
   "metadata": {},
   "source": [
    "## Doing some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dbe6a4-15d3-433f-afd4-e0541f645b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining class labels\n",
    "class_labels = [\"Healthy\", \"Unhealthy\"]\n",
    "\n",
    "# Selecting first three test samples\n",
    "X_test_sample = X_test[:3]  # MFCC features\n",
    "y_true_sample = np.argmax(y_test[:3], axis=1)  # Convert one-hot to class index\n",
    "\n",
    "# Get predictions\n",
    "y_pred_probs = model.predict(X_test_sample)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Print out predictions\n",
    "for i in range(3):\n",
    "    print(f\"audio {i+1}: Predicted = {class_labels[y_pred[i]]}, Actual = {class_labels[y_true_sample[i]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67b3eb-4214-4cd4-a386-a5739ef1944a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
